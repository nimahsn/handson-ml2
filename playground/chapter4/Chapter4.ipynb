{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Training  Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a linear model makes a predictipon by simply computing a weighted sum of the input features, plus a constant called the bias term:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y}=\\theta_{0}+\\theta_{1} x_{1}+\\theta_{2} x_{2}+\\cdots+\\theta_{n} x_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y}=h_{\\theta}(\\mathbf{x})=\\boldsymbol{\\theta} \\cdot \\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\widehat{\\boldsymbol{\\theta}}=\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\top} \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This equation gives us the weights directly\n",
    "- pseudo inverse can be used instead of inverse, as $\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)$ might be singular, as result of redundant features or not enough instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit learn LinearRegression class uses normal equations and is based on scipy.linalg.lstsq() which computes pseudo inverse using SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computing inverse of this matrix has a computational complexity of $O(n^2.4)$ to $O(n^3)$ depending on the implementation. scikit learn approach's complexity is about $O(n^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal equation and svd method get very slow as numver of features ($n$) grows. On the positive side they are linear regarding to the number of instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent algorithm tweaks parameters iteratively in order to minimize a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch gradient descent computes the partial derivative if the cost function with regard to parameter $\\theta_j$ :\n",
    "$$\\frac{\\partial}{\\partial \\theta_{j}} \\operatorname{MSE}(\\boldsymbol{\\theta})=\\frac{2}{m} \\sum_{i=1}^{m}\\left(\\boldsymbol{\\theta}^{\\top} \\mathbf{x}^{(i)}-y^{(i)}\\right) x_{j}^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re write this in the form below to compute all the derivatives in one go.The gradient vector contains all the derivatives of the cost function:\n",
    "$$\\nabla_{\\theta} \\operatorname{MSE}(\\boldsymbol{\\theta})=\\left(\\begin{array}{c}\n",
    "\\frac{\\partial}{\\partial \\theta_{0}} \\operatorname{MSE}(\\boldsymbol{\\theta}) \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_{1}} \\operatorname{MSE}(\\boldsymbol{\\theta}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_{\\mathrm{n}}} \\operatorname{MSE}(\\boldsymbol{\\theta})\n",
    "\\end{array}\\right)=\\frac{2}{m} \\mathbf{X}^{\\top}(\\mathbf{X} \\boldsymbol{\\theta}-\\mathbf{y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This method computes the derivatives over the whole training set $\\mathbf{X}$ at each step. this is why it's called Batch Gradient Descent. As a result it gets slow on very large training sets. However, Gradient Descent scales well with the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the gradient vector, we can calculate new weights:\n",
    "$$\\boldsymbol{\\theta}^{(\\text {next step })}=\\boldsymbol{\\theta}-\\eta \\nabla_{\\boldsymbol{\\theta}} \\operatorname{MSE}(\\boldsymbol{\\theta})$$ where $\\eta$ is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent, unlike Batch Gradient Descent, picks a random instance in training set at every training step and computes gradients based on that single instance. Over time it will get close to the minimum, but once it gets there it will continue to bounce around, never settling down. So once the algorithm stops, the final parameter values are good, but not optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- faster convergence\n",
    "- more likely to find global minimum\n",
    "- can be implemented as an out-of-core algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the randomness is good for escaping from local optima by jumping over, it's bad as it can never settle at the minimum. one solution to this problem is to gradually reduce the learning rate. the learning rate should not be reduced too quickly or too slowly. The function that determines the learning rate at each iteration is called the learning schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SGD implementation, epochs are used instead of iterations. While BGD calculates over the whole data set in every iteration, SGD calculates derivatives over every instance separately in every epoch; so it goes through the training set on each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using SGD, the training instances must be independent and identically disturbed to ensure that the parameters get pulled toward the global optimum. A simple way to ensure this is to shuffle the instances\n",
    "during training (e.g., pick each instance randomly, or shuffle the training set at the\n",
    "beginning of each epoch). If you do not shuffle the instances—for example, if the\n",
    "instances are sorted by label—then SGD will start by optimizing for one label, then the\n",
    "next, and so on, and it will not settle close to the global minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn has implemented SGD in SGDRegressor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Batch GD, instead of training on whole training set as in BGD or training on one instance as in SGD on each step, computes gradients on a small random set of instances. Mini-Batch GD benefits from hardware optimization of matrix operations, especially when using GPUs. It will end up walking around a bit closer to the minimum than\n",
    "Stochastic GD—but it may be harder for it to escape from local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{llllll}\n",
    "\\hline \\text { Algorithm } & \\begin{array}{l}\n",
    "\\text { Large } \\\\\n",
    "m\n",
    "\\end{array} & \\begin{array}{l}\n",
    "\\text { Out-of-core } \\\\\n",
    "\\text { support }\n",
    "\\end{array} & \\begin{array}{l}\n",
    "\\text { Large } \\\\\n",
    "\\boldsymbol{n}\n",
    "\\end{array} & \\text { Hyperparams } & \\begin{array}{l}\n",
    "\\text { Scaling } \\\\\n",
    "\\text { required }\n",
    "\\end{array} & \\text { Scikit-Learn } \\\\\n",
    "\\hline \\begin{array}{l}\n",
    "\\text { Normal } \\\\\n",
    "\\text { Equation }\n",
    "\\end{array} & \\text { Fast } & \\text { No } & \\text { Slow } & 0 & \\text { No } & \\text { N/A } \\\\\n",
    "\\hline \\text { SVD } & \\text { Fast } & \\text { No } & \\text { Slow } & 0 & \\text { No } & \\text { LinearRegression } \\\\\n",
    "\\hline \\text { Batch GD } & \\text { Slow } & \\text { No } & \\text { Fast } & 2 & \\text { Yes } & \\text { SGDRegressor } \\\\\n",
    "\\hline \\begin{array}{l}\n",
    "\\text { Stochastic } \\\\\n",
    "\\text { GD }\n",
    "\\end{array} & \\text { Fast } & \\text { Yes } & \\text { Fast } & \\geq 2 & \\text { Yes } & \\text { SGDRegressor } \\\\\n",
    "\\hline \\begin{array}{l}\n",
    "\\text { Mini-batch } \\\\\n",
    "\\text { GD }\n",
    "\\end{array} & \\text { Fast } & \\text { Yes } & \\text { Fast } & \\geq 2 & \\text { Yes } & \\text { SGDRegressor }\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use linear regression models to train non linear data by adding combinations and higher degrees of features. This can be done with scikit-learn PloynomialFeatures class from <c>preprocessing</c> package. Note that when there are multiple features, Polynomial Regression is capable\n",
    "of finding relationships between features (which is something a plain Linear\n",
    "Regression model cannot do). This is made possible by the fact that\n",
    "PolynomialFeatures also adds all combinations of features up to the given\n",
    "degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to see if a model is over-fitting or not was to use cross-validation metrics. Another way to tell is to look at the learning curves of a model; these are plots of model performance on the training set and validation set as function of the training set size or the training iteration (checkout training_models notebook for examples).\n",
    "generally the train error increases as size of the training set grows, but validation error decreases. Eventually these two get close to each other and end up in plateau and don't change as the training set gets bigger. If both curves reach a plateau close to each other and relatively high; the model is probably under-fitting. On the other hand if plateaus are far from each other (low train error and high validation error) the model is over-fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model's generalization error can be expressed as sum of three errors:\n",
    "- #### Bias\n",
    "this part of error is due to wrong assumptions, such as assuming that data is linear when it's actually quadratic. A high-bias model is likely to under-fit the training data.\n",
    "- #### Variance\n",
    "This part is due to the model’s excessive sensitivity to small\n",
    "variations in the training data. A model with many degrees of\n",
    "freedom (such as a high-degree polynomial model) is likely to have\n",
    "high variance and thus overfit the training data.\n",
    "- #### Irreducible error\n",
    "This part is due to the noisiness of the data itself.\n",
    "\n",
    "Increasing a model’s complexity will typically increase its variance and reduce its bias. Conversely, reducing a model’s complexity increases its bias and reduces its variance. This is why it is called a trade-off.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression is a regularized version of linear regression which a regularization term equal to $\\alpha \\sum_{i=1}^{n} \\theta_{i}^{2}$ is added to cost function. The hyperparameter $\\alpha$ controls how much you want to regularize the model.\n",
    "$$J(\\boldsymbol{\\theta})=\\operatorname{MSE}(\\boldsymbol{\\theta})+\\alpha \\frac{1}{2} \\sum_{i=1}^{n} \\theta_{i}^{2}$$\n",
    "Note that bias therm $\\theta_0$ is not regularized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we define $\\mathbf{w}$ as the vector of feature weights (θ1 to θn), then the\n",
    "regularization term is equal to $1 / 2\\left(\\|\\mathbf{w}\\|_{2}\\right)^{2},$ where $\\|\\mathbf{w}\\|_{2}$represents the $\\ell_{2}$ norm of the weight vector. For Gradient Descent, just add $\\alpha\\mathbf{w}$ to the $\\operatorname{MSE}$ gradient vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### WARNING\n",
    "It is important to scale the data before performing Ridge Regression, as it is sensitive to the scale of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression can be implemented in both closed form using a matrix factorization technique (Cholesky) and Gradient Descent.<br>\n",
    "Closed Form method can show in the following form in which $\\mathbf{A}$ is the $(n+1)×(n+1)$ identity matrix, except with a 0 in the top-left cell. corresponding to the bias term:\n",
    "$$\\widehat{\\boldsymbol{\\theta}}=\\left(\\mathbf{X}^{\\top} \\mathbf{X}+\\alpha \\mathbf{A}\\right)^{-1} \\mathbf{X}^{\\top} \\mathbf{y}$$\n",
    "Ridge Regression can be performed with scikit-learn Ridge class in linear_models package with solver=\"cholesky\" parameter; and using SGD with penalty=\"l2\" parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Least Absolute Shrinkage and Selection Operator Regression</i> or Lasso Regression, just like Ridge Regression, adds a regularization term to cost function; but it uses $\\ell_1$ norm of the weights.\n",
    "$$J(\\boldsymbol{\\theta})=\\operatorname{MSE}(\\boldsymbol{\\theta})+\\alpha \\sum_{i=1}^{n}\\left|\\theta_{i}\\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important characteristic of Lass Regression is that it tends to eliminate unimportant features by setting their weights to zero. Actually Lasso performs an automatic feature selection and outputs a sparse model. checkout figure 4-19 of book for more insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in Ridge Regression, gradients get smaller as the parameters get closer to global optimum, so gradient descent slows down which helps convergence, while with lasso regression, gradient descent bounces around the optimum. Also features with less importance get smaller as $\\alpha$ increases, but they never get eliminated entirely as in Lasso Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that Lasso cost function is not differentiable at $\\theta_i = 0$, but gradient descent still works fine if we use a sub-gradient vector $\\mathbf{g}$ instead when any $\\theta_i = 0$.\n",
    "$$g(\\boldsymbol{\\theta}, J)=\\nabla_{\\boldsymbol{\\theta}} \\operatorname{MSE}(\\boldsymbol{\\theta})+\\alpha\\left(\\begin{array}{c}\n",
    "\\operatorname{sign}\\left(\\theta_{1}\\right) \\\\\n",
    "\\operatorname{sign}\\left(\\theta_{2}\\right) \\\\\n",
    "\\vdots \\\\\n",
    "\\operatorname{sign}\\left(\\theta_{n}\\right)\n",
    "\\end{array}\\right) \\quad \\text { where } \\operatorname{sign}\\left(\\theta_{i}\\right)=\\left\\{\\begin{array}{cl}\n",
    "-1 & \\text { if } \\theta_{i}<0 \\\\\n",
    "0 & \\text { if } \\theta_{i}=0 \\\\\n",
    "+1 & \\text { if } \\theta_{i}>0\n",
    "\\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression is available through Lasso class in linear_model package from Scikit-Learn. We can also use SGDResgressor with penalty=\"l1\" parameter instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic net is a middle ground between Ridge and Lasso Regression. The regularization term is a simple mix of both Ridge and\n",
    "Lasso’s regularization terms, and you can control the mix ratio $r$.\n",
    "$$J(\\boldsymbol{\\theta})=\\operatorname{MSE}(\\boldsymbol{\\theta})+r \\alpha \\sum_{i=1}^{n}\\left|\\theta_{i}\\right|+\\frac{1-r}{2} \\alpha \\sum_{i=1}^{n} \\theta_{i}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net is accessible through sickit learn ElasticNet class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when should you use plain Linear Regression (i.e., without any\n",
    "regularization), Ridge, Lasso, or Elastic Net? It is almost always preferable\n",
    "to have at least a little bit of regularization, so generally you should avoid\n",
    "plain Linear Regression. Ridge is a good default, but if you suspect that only\n",
    "a few features are useful, you should prefer Lasso or Elastic Net because\n",
    "they tend to reduce the useless features’ weights down to zero, as we have\n",
    "discussed. In general, Elastic Net is preferred over Lasso because Lasso may\n",
    "behave erratically when the number of features is greater than the number of\n",
    "training instances or when several features are strongly correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very different way to regularize iterative learning algorithms such as\n",
    "Gradient Descent is to stop training as soon as the validation error reaches a\n",
    "minimum.  As the epochs go by the algorithm learns, and\n",
    "its prediction error (RMSE) on the training set goes down, along with its\n",
    "prediction error on the validation set. After a while though, the validation\n",
    "error stops decreasing and starts to go back up. This indicates that the model\n",
    "has started to overfit the training data. With early stopping you just stop\n",
    "training as soon as the validation error reaches the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
